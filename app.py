# -*- coding: utf-8 -*-
# çµ±è¨ˆæª¢å®šå°å¹«æ‰‹ï¼šï¼ˆMK/SMK + ANOVA/Kruskalï¼‰
# ä½œè€…ï¼šä½  & ChatGPT

import os
import io
from math import erf, sqrt
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import norm

# ==== åŸºæœ¬è¨­å®š ====
st.set_page_config(page_title="çµ±è¨ˆæª¢å®šå°å¹«æ‰‹", layout="wide")
st.title("ğŸ“Š çµ±è¨ˆæª¢å®šå°å¹«æ‰‹")

PHASE_LEVELS = ["æ–½å·¥å‰", "æ–½å·¥éšæ®µ"]  # äºŒéšæ®µå›ºå®šæ’åº

# ==== å…±ç”¨å·¥å…· ====
@st.cache_data(show_spinner=False)
def read_uploaded(uploaded_file) -> pd.DataFrame | None:
    """è®€å–ä¸Šå‚³æª”ï¼Œæ”¯æ´ CSV / XLSX / XLS / XLSBï¼Œä¸¦è‡ªå‹•é¸ç¬¬ä¸€å€‹å·¥ä½œè¡¨ï¼ˆXLSX/XLS/XLSBï¼‰ã€‚
       è‹¥è¦é¸ sheetï¼Œå¯æŠŠæ­¤å‡½å¼æ”¹å›å›å‚³ ExcelFile ç‰©ä»¶ï¼Œå†åœ¨ä¸»æµç¨‹åšé¸å–®ã€‚"""
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    suffix = os.path.splitext(name)[1]
    try:
        if suffix == ".csv":
            return pd.read_csv(uploaded_file)
        elif suffix == ".xlsx":
            return pd.read_excel(uploaded_file, engine="openpyxl")
        elif suffix == ".xls":
            return pd.read_excel(uploaded_file, engine="xlrd")
        elif suffix == ".xlsb":
            return pd.read_excel(uploaded_file, engine="pyxlsb")
        else:
            st.error(f"ä¸æ”¯æ´çš„å‰¯æª”åï¼š{suffix}")
            return None
    except ImportError as e:
        st.error(
            "ç¼ºå°‘å°æ‡‰å¼•æ“å¥—ä»¶ï¼š\n"
            "- .xlsx éœ€è¦ openpyxl\n"
            "- .xls éœ€è¦ xlrd==1.2.0\n"
            "- .xlsb éœ€è¦ pyxlsb\n"
            f"\nåŸå§‹éŒ¯èª¤ï¼š\n{e}"
        )
        return None
    except Exception as e:
        st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
        return None

def parse_year_quarter(v: str) -> tuple[int | float, int | float]:
    """æ”¯æ´ '106Q4' æˆ–æ—¥æœŸï¼›å›å‚³ (year, quarter)"""
    v = str(v)
    if "Q" in v:
        y, q = v.split("Q")
        try:
            return int(y), int(q)
        except:
            return np.nan, np.nan
    try:
        dt = pd.to_datetime(v)
        return dt.year, ((dt.month - 1) // 3 + 1)
    except:
        return np.nan, np.nan

def to_numeric_clean(val):
    """æŠŠ '<0.02'ã€'ND'ã€'â€”'ã€'-' æ¸…æˆæ•¸å€¼ï¼›å…¶ä»–ç„¡æ³•è½‰çš„è®Š NaNã€‚"""
    if pd.isna(val):
        return np.nan
    if isinstance(val, str):
        val = (
            val.strip()
            .replace("<", "")
            .replace("ND", "")
            .replace("â€”", "")
            .replace("-", "")
            .strip()
        )
        if val == "":
            return np.nan
    try:
        return float(val)
    except:
        return np.nan

def build_time_index(df: pd.DataFrame) -> pd.DataFrame:
    """æ–°å¢ year, quarter, time_indexï¼ˆå¹´*4+å­£ï¼‰ï¼›è‹¥åªæœ‰å¹´æœˆäº¦å¯è½‰å­£"""
    years, quarters = zip(*[parse_year_quarter(v) for v in df["ç›£æ¸¬æ™‚é–“"].astype(str)])
    df["year"] = years
    df["quarter"] = quarters
    df["time_index"] = df.apply(
        lambda r: r["year"] * 4 + r["quarter"]
        if pd.notna(r["year"]) and pd.notna(r["quarter"])
        else np.nan,
        axis=1,
    )
    return df

def mk_test(x_order: pd.Series, y_vals: pd.Series):
    """Kendall tau è¿‘ä¼¼ MKï¼›è¨ˆç®— tau, p, Sen's slopeï¼ˆä¸­ä½æ•¸æ–œç‡ï¼‰ï¼Œå›å‚³ dict æˆ– Noneã€‚"""
    mask = (~pd.isna(x_order)) & (~pd.isna(y_vals))
    if mask.sum() < 4:
        return None
    t = np.asarray(pd.to_numeric(x_order[mask], errors="coerce"))
    y = np.asarray(pd.to_numeric(y_vals[mask], errors="coerce"))
    ok = (~np.isnan(t)) & (~np.isnan(y))
    t, y = t[ok], y[ok]
    if len(t) < 4:
        return None

    tau, p = stats.kendalltau(t, y)

    slopes = []
    for i in range(len(y) - 1):
        for j in range(i + 1, len(y)):
            if t[j] != t[i]:
                slopes.append((y[j] - y[i]) / (t[j] - t[i]))
    beta = np.median(slopes) if slopes else np.nan
    return {"tau": float(tau), "p": float(p), "sen": float(beta), "n": int(len(y))}

def smk_test_yearly_by_quarter(df_q: pd.DataFrame, value_col: str):
    """å­£ç¯€ Mannâ€“Kendallï¼ˆä»¥å­£ç¯€åˆ†çµ„ï¼Œé€å­£åœ¨ã€Œå¹´ä»½ã€ä¸Šåš MKï¼Œå½™ç¸½ S/Var(S) å¾— Z èˆ‡ pï¼‰ï¼Œä¸¦å½™æ•´ Sen's slope çš„ä¸­ä½æ•¸ã€‚
       å›å‚³ dictï¼š{'Z':, 'p':, 'sen':, 'n':} æˆ– None"""
    if "year" not in df_q.columns or "quarter" not in df_q.columns:
        return None
    S_total, Var_total = 0.0, 0.0
    sen_list = []
    n_total = 0

    for q, sub in df_q.groupby("quarter"):
        # åœ¨åŒä¸€å­£å…§ï¼Œä½¿ç”¨å¹´ä»½åšæ™‚é–“è»¸
        mkres = mk_test(sub["year"], sub[value_col])
        if mkres is None:
            continue
        n = mkres["n"]
        # ä»¥ tau è¿‘ä¼¼ S èˆ‡ Var(S)
        S_q = mkres["tau"] * n * (n - 1) / 2.0
        Var_q = n * (n - 1) * (2 * n + 5) / 18.0
        S_total += S_q
        Var_total += Var_q
        n_total += n
        sen_list.append(mkres["sen"])  # æ–œç‡ä»¥å„å­£çš„ beta ä¸­ä½æ•¸å†å–ä¸­ä½

    if Var_total <= 0:
        return None

    # é€£çºŒæ€§ä¿®æ­£
    if S_total > 0:
        Z = (S_total - 1) / np.sqrt(Var_total)
    elif S_total < 0:
        Z = (S_total + 1) / np.sqrt(Var_total)
    else:
        Z = 0.0

    p = 2 * norm.sf(abs(Z))  # é›™å°¾

    sen = np.nanmedian(sen_list) if len(sen_list) > 0 else np.nan
    return {"Z": float(Z), "p": float(p), "sen": float(sen), "n": int(n_total)}

def check_normality_by_group(df, group_col, y_col):
    """é€ç¾¤ Shapiroï¼›ç•¶æ‰€æœ‰ç¾¤ p>=0.05 è¦–ç‚ºè¿‘ä¼¼å¸¸æ…‹ã€‚"""
    res = []
    for g, sub in df.groupby(group_col):
        x = pd.to_numeric(sub[y_col], errors="coerce").dropna()
        if len(x) >= 3:
            W, p = stats.shapiro(x)
            res.append(p >= 0.05)
    return all(res) if len(res) >= 2 else False

def levene_equal_var(df, group_col, y_col):
    """Levene ç­‰è®Šç•°æª¢å®šï¼›å›å‚³ (ç­‰è®Šç•°?, på€¼)"""
    groups = [
        pd.to_numeric(sub[y_col], errors="coerce").dropna()
        for _, sub in df.groupby(group_col)
    ]
    groups = [g for g in groups if len(g) >= 2]
    if len(groups) >= 2:
        stat, p = stats.levene(*groups)
        return p >= 0.05, float(p)
    return False, np.nan

# ==== å´æ¬„è®€æª” & ç¯©é¸ ====
st.sidebar.header("è³‡æ–™ä¾†æº")
uploaded = st.sidebar.file_uploader("ä¸Šå‚³è³‡æ–™ï¼ˆCSV / Excelï¼‰", type=["csv", "xlsx", "xls", "xlsb"])
df = read_uploaded(uploaded)
if df is None:
    st.stop()

# å¿…è¦æ¬„ä½æª¢æŸ¥
must_cols = ["ç›£æ¸¬åœ°é»", "éšæ®µ", "ç›£æ¸¬æ™‚é–“"]
missing = [c for c in must_cols if c not in df.columns]
if missing:
    st.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing}ï¼ˆè‡³å°‘æ‡‰æœ‰ ç›£æ¸¬åœ°é»/éšæ®µ/ç›£æ¸¬æ™‚é–“ï¼‰")
    st.stop()

# è½‰æ•¸å€¼ï¼ˆé™¤äº†æè¿°æ¬„ä½ï¼‰
value_cols = [c for c in df.columns if c not in ["ç›£æ¸¬åœ°é»", "éšæ®µ", "ç›£æ¸¬æ™‚é–“"]]
for c in value_cols:
    df[c] = df[c].apply(to_numeric_clean)

df = build_time_index(df)
df["éšæ®µ"] = pd.Categorical(df["éšæ®µ"], categories=PHASE_LEVELS, ordered=True)

stations = sorted(df["ç›£æ¸¬åœ°é»"].dropna().unique().tolist())
phases = [p for p in PHASE_LEVELS if p in df["éšæ®µ"].unique()]
numeric_cols = [c for c in value_cols if pd.api.types.is_numeric_dtype(df[c])]

st.sidebar.header("ç¯©é¸æ¢ä»¶")
sel_stations = st.sidebar.multiselect("é¸æ“‡æ¸¬ç«™ï¼ˆå¯å¤šé¸ï¼‰", stations, default=stations[:1] if stations else [])
sel_phases = st.sidebar.multiselect("é¸æ“‡éšæ®µï¼ˆå¯å¤šé¸ï¼‰", phases, default=phases)
sel_metrics = st.sidebar.multiselect("é¸æ“‡æ°´è³ªæŒ‡æ¨™ï¼ˆå¯å¤šé¸ï¼‰", numeric_cols, default=numeric_cols[:3] if numeric_cols else [])
use_smk = st.sidebar.checkbox("ä½¿ç”¨å­£ç¯€ Mannâ€“Kendallï¼ˆSMKï¼‰", value=False)

fdf = df[df["ç›£æ¸¬åœ°é»"].isin(sel_stations) & df["éšæ®µ"].isin(sel_phases)]

st.write(f"ç›®å‰ç¯©é¸ï¼š**{len(fdf)}** ç­†ï¼›æ¸¬ç«™ **{len(sel_stations)}**ï¼›éšæ®µ **{len(sel_phases)}**")

# ==== Tabs ====
tab1, tab2 = st.tabs(["ğŸ•’ æ™‚é–“è¶¨å‹¢ï¼ˆMK/SMKï¼‰", "ğŸ·ï¸ è·¨éšæ®µå·®ç•°ï¼ˆåŒæ¸¬ç«™å…§ï¼‰"])

# ========== Tab 1ï¼šæ™‚é–“è¶¨å‹¢ ==========
with tab1:
    st.subheader("æ™‚é–“è¶¨å‹¢åˆ†æï¼ˆæ¯æ¸¬ç«™ Ã— æŒ‡æ¨™ï¼‰")
    if not sel_metrics:
        st.info("è«‹åœ¨å·¦å´é¸æ“‡è‡³å°‘ 1 å€‹æ°´è³ªæŒ‡æ¨™")
    else:
        rows = []
        for stn, d1 in fdf.groupby("ç›£æ¸¬åœ°é»"):
            for m in sel_metrics:
                sub = d1[["ç›£æ¸¬æ™‚é–“", "year", "quarter", "time_index", m, "éšæ®µ"]].dropna(subset=[m])
                if len(sub) < 4:
                    rows.append({
                        "æ¸¬ç«™": stn, "æŒ‡æ¨™": m, "æ–¹æ³•": "SMK" if use_smk else "MK",
                        "n": len(sub), "tau/Z": np.nan, "på€¼": np.nan,
                        "Senæ–œç‡(æ¯æœŸ)": np.nan, "çµè«–": "æ¨£æœ¬ä¸è¶³"
                    })
                    continue

                if use_smk:
                    res = smk_test_yearly_by_quarter(sub, m)
                    if res is None:
                        rows.append({
                            "æ¸¬ç«™": stn, "æŒ‡æ¨™": m, "æ–¹æ³•": "SMK", "n": len(sub),
                            "tau/Z": np.nan, "på€¼": np.nan, "Senæ–œç‡(æ¯æœŸ)": np.nan, "çµè«–": "æ¨£æœ¬ä¸è¶³/è³‡æ–™ä¸è¶³"
                        })
                    else:
                        concl = "ä¸Šå‡" if res["Z"] > 1.96 else ("ä¸‹é™" if res["Z"] < -1.96 else "ç„¡é¡¯è‘—è¶¨å‹¢")
                        rows.append({
                            "æ¸¬ç«™": stn, "æŒ‡æ¨™": m, "æ–¹æ³•": "SMK", "n": res["n"],
                            "tau/Z": res["Z"], "på€¼": res["p"], "Senæ–œç‡(æ¯æœŸ)": res["sen"], "çµè«–": concl
                        })
                else:
                    res = mk_test(sub["time_index"], sub[m])
                    if res is None:
                        rows.append({
                            "æ¸¬ç«™": stn, "æŒ‡æ¨™": m, "æ–¹æ³•": "MK", "n": len(sub),
                            "tau/Z": np.nan, "på€¼": np.nan, "Senæ–œç‡(æ¯æœŸ)": np.nan, "çµè«–": "æ¨£æœ¬ä¸è¶³"
                        })
                    else:
                        concl = "ä¸Šå‡" if (res["tau"] > 0 and res["p"] < 0.05) else \
                                ("ä¸‹é™" if (res["tau"] < 0 and res["p"] < 0.05) else "ç„¡é¡¯è‘—è¶¨å‹¢")
                        rows.append({
                            "æ¸¬ç«™": stn, "æŒ‡æ¨™": m, "æ–¹æ³•": "MK", "n": res["n"],
                            "tau/Z": res["tau"], "på€¼": res["p"], "Senæ–œç‡(æ¯æœŸ)": res["sen"], "çµè«–": concl
                        })

        res_df = pd.DataFrame(rows)
        # æ•¸å€¼æ ¼å¼
        if not res_df.empty:
            for c in ["tau/Z", "på€¼", "Senæ–œç‡(æ¯æœŸ)"]:
                if c in res_df.columns:
                    res_df[c] = pd.to_numeric(res_df[c], errors="coerce")
        st.dataframe(res_df, use_container_width=True)

        # å°åœ–ï¼ˆæŒ‰æ¸¬ç«™ Ã— æŒ‡æ¨™ï¼‰
        st.caption("ä¸‹æ–¹ç‚ºç°¡è¦è¶¨å‹¢åœ–ï¼ˆåŸå§‹å€¼ vs ç›£æ¸¬æ™‚é–“ï¼‰")
        for stn, d1 in fdf.groupby("ç›£æ¸¬åœ°é»"):
            st.markdown(f"### æ¸¬ç«™ï¼š{stn}")
            cols = st.columns(min(3, len(sel_metrics)) or 1)
            for i, m in enumerate(sel_metrics):
                sub = d1[["ç›£æ¸¬æ™‚é–“", "time_index", m]].dropna()
                if len(sub) >= 2:
                    ax = cols[i % len(cols)]
                    sub2 = sub.sort_values("time_index").set_index("ç›£æ¸¬æ™‚é–“")
                    ax.line_chart(sub2[m])

        # å¯ä¸‹è¼‰çµæœ
        st.download_button(
            label="â¬‡ï¸ ä¸‹è¼‰æ™‚é–“è¶¨å‹¢æª¢å®šçµæœï¼ˆCSVï¼‰",
            data=res_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="time_trend_MK_SMK_results.csv",
            mime="text/csv",
        )

# ========== Tab 2ï¼šè·¨éšæ®µå·®ç•° ==========
with tab2:
    st.subheader("è·¨éšæ®µå·®ç•°")
    st.info("é¸æ“‡å–®ä¸€æ¸¬ç«™èˆ‡å–®ä¸€æŒ‡æ¨™ï¼Œå°äºŒéšæ®µåš ANOVA æˆ– Kruskalâ€“Wallisï¼›å¯é¸æ“‡äº‹å¾Œæ¯”è¼ƒï¼ˆTukey / Dunnï¼‰")

    stn2 = st.selectbox("æ¸¬ç«™", options=sel_stations if sel_stations else stations)
    m2 = st.selectbox("æŒ‡æ¨™", options=sel_metrics if sel_metrics else numeric_cols)
    do_posthoc = st.checkbox("é¡¯è‘—æ™‚é€²è¡Œäº‹å¾Œæ¯”è¼ƒï¼ˆTukey / Dunnï¼‰", value=False)

    if stn2 and m2:
        d2 = df[(df["ç›£æ¸¬åœ°é»"] == stn2) & (df["éšæ®µ"].isin(sel_phases))][["éšæ®µ", m2]].dropna()
        d2["éšæ®µ"] = pd.Categorical(d2["éšæ®µ"], categories=PHASE_LEVELS, ordered=True)

        if d2["éšæ®µ"].nunique() < 2:
            st.warning("è‡³å°‘éœ€è¦å…©å€‹ä»¥ä¸Šéšæ®µæ‰å¯æ¯”è¼ƒã€‚")
        else:
            normal_like = check_normality_by_group(d2, "éšæ®µ", m2)
            eqvar, p_lev = levene_equal_var(d2, "éšæ®µ", m2)
            st.write(f"å¸¸æ…‹æ€§ï¼ˆé€éšæ®µ Shapiroï¼‰ï¼š{'è¿‘ä¼¼å¸¸æ…‹' if normal_like else 'éå¸¸æ…‹/ä¸ç¢ºå®š'}")
            st.write(f"Levene ç­‰è®Šç•°æª¢å®š p={p_lev:.3f} â†’ {'å¯è¦–ç‚ºç­‰è®Šç•°' if eqvar else 'ä¸ç­‰è®Šç•°'}")

            groups = [
                pd.to_numeric(sub[m2], errors="coerce").dropna().values
                for _, sub in d2.groupby("éšæ®µ")
            ]
            groups = [g for g in groups if len(g) > 0]

            posthoc_note = ""
            if len(groups) >= 2:
                if normal_like and eqvar and len(groups) >= 3:
                    F, p = stats.f_oneway(*groups)
                    st.success(f"One-way ANOVAï¼šF = {F:.3f}, p = {p:.5f}")
                    posthoc_note = "Tukey HSDï¼ˆstatsmodelsï¼‰"
                    main_sig = (p < 0.05)
                else:
                    H, p = stats.kruskal(*groups)
                    st.success(f"Kruskalâ€“Wallisï¼šH = {H:.3f}, p = {p:.5f}")
                    posthoc_note = "Dunnï¼ˆscikit-posthocsï¼‰"
                    main_sig = (p < 0.05)

                st.caption("è‹¥é¡¯è‘—ï¼Œå»ºè­°å°åšäº‹å¾Œæ¯”è¼ƒï¼š" + posthoc_note)

                st.write("æè¿°çµ±è¨ˆï¼ˆå„éšæ®µï¼‰")
                st.dataframe(
                    d2.groupby("éšæ®µ")[m2].describe()[["count", "mean", "std", "min", "50%", "max"]],
                    use_container_width=True,
                )

                st.write("ç®±å½¢åœ–")
                fig, ax = plt.subplots()
                d2.boxplot(column=m2, by="éšæ®µ", grid=False, ax=ax)
                ax.set_title(f"{stn2} - {m2} by éšæ®µ")
                ax.set_ylabel(m2)
                fig.suptitle("")
                st.pyplot(fig)

                # äº‹å¾Œæ¯”è¼ƒ
                if do_posthoc and main_sig:
                    try:
                        if normal_like and eqvar and len(groups) >= 3:
                            # Tukey HSD
                            import statsmodels.api as sm
                            from statsmodels.stats.multicomp import pairwise_tukeyhsd
                            endog = pd.to_numeric(d2[m2], errors="coerce")
                            groups_label = d2["éšæ®µ"].astype(str)
                            tuk = pairwise_tukeyhsd(endog=endog, groups=groups_label, alpha=0.05)
                            st.subheader("Tukey HSD äº‹å¾Œæ¯”è¼ƒ")
                            st.text(str(tuk))
                        else:
                            # Dunn
                            import scikit_posthocs as sp
                            # Dunn éœ€è¦åŸå§‹è³‡æ–™ + åˆ†ç¾¤
                            ph = sp.posthoc_dunn(d2, val_col=m2, group_col="éšæ®µ", p_adjust="bonferroni")
                            st.subheader("Dunn äº‹å¾Œæ¯”è¼ƒï¼ˆBonferroni æ ¡æ­£ï¼‰")
                            st.dataframe(ph, use_container_width=True)
                    except Exception as e:
                        st.warning(f"äº‹å¾Œæ¯”è¼ƒæœªèƒ½åŸ·è¡Œï¼š{e}\nè«‹ç¢ºèª requirements å·²å®‰è£ statsmodels / scikit-posthocsã€‚")

            # ä¸‹è¼‰æ•´ç†å¾Œçš„åˆ†çµ„è³‡æ–™
            st.download_button(
                label="â¬‡ï¸ ä¸‹è¼‰è·¨éšæ®µè³‡æ–™ï¼ˆCSVï¼‰",
                data=d2.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{stn2}_{m2}_by_phase.csv",
                mime="text/csv",
            )

# ==== é å°¾èªªæ˜ ====
with st.expander("èªªæ˜ / æ³¨æ„äº‹é …"):
    st.markdown(
        """
- **MK / SMK**ï¼šMK ä½¿ç”¨ `time_index = å¹´*4+å­£`ï¼›SMK åœ¨æ¯ä¸€å­£å…§å°å¹´ä»½åš MKï¼Œå½™ç¸½ S èˆ‡ Var(S) å¾— Z èˆ‡ pã€‚
- **Sen's slope**ï¼šå›å ±ç‚ºã€Œæ¯æœŸã€è®ŠåŒ–é‡ï¼›è‹¥ä½ çš„æœŸ=å­£ï¼Œå¹´åŒ–è«‹ä¹˜ä»¥ 4ã€‚
- **å¸¸æ…‹èˆ‡ç­‰è®Šç•°**ï¼šè·¨éšæ®µå·®ç•°çš„ä¸»æª¢å®šç”±å¸¸æ…‹æ€§èˆ‡ç­‰è®Šç•°æ±ºå®šï¼šå¸¸æ…‹+ç­‰è®Šç•°â†’ANOVAï¼›å¦å‰‡â†’Kruskalâ€“Wallisã€‚
- **äº‹å¾Œæ¯”è¼ƒ**ï¼šANOVA é¡¯è‘—â†’Tukeyï¼›Kruskal é¡¯è‘—â†’Dunnã€‚è«‹åœ¨ `requirements.txt` å®‰è£å°æ‡‰å¥—ä»¶ã€‚
- **è³‡æ–™æ¸…ç†**ï¼šå­—ä¸²ä¸­çš„ `<`ã€`ND`ã€`â€”`ã€`-` æœƒè¢«ç§»é™¤å†è½‰æ•¸å€¼ï¼Œç„¡æ³•è½‰è€…ç‚º NaNã€‚
        """
    )

